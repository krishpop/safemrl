import safemrl.envs.minitaur
import safemrl.utils.metrics
import safemrl.utils.misc
import safemrl.algos.agents
import tf_agents.environments.suite_pybullet
import tf_agents.networks.actor_distribution_network

EP_LEN = 500
ENV_STR = "MinitaurGoalVelocityEnv-v0"
ENV_LOAD_FN = @suite_pybullet.load
EVAL_ENV_LOAD_FN = @suite_pybullet.load
ENV_LOAD_FN_MONITOR = @env_loader/suite_pybullet.load
EVAL_ENV_LOAD_FN_MONITOR = @eval_env_loader/suite_pybullet.load
TRAIN_MONITOR_FREQ = 100
EVAL_MONITOR_FREQ = 10
VID_DIR = './rollouts'
EVAL_VID_DIR = './eval_rollouts'

suite_pybullet.load.gym_env_wrappers = (@minitaur.TaskAgnWrapper, @minitaur.CurrentVelWrapper)
env_loader/suite_pybullet.load.gym_env_wrappers =  (@minitaur.TaskAgnWrapper,
                                                    @minitaur.CurrentVelWrapper,
                                                    @train_monitor/misc.monitor_freq())
train_monitor/misc.monitor_freq.freq = %TRAIN_MONITOR_FREQ
train_monitor/misc.monitor_freq.vid_dir = %VID_DIR

eval_env_loader/suite_pybullet.load.gym_env_wrappers =  (@minitaur.TaskAgnWrapper,
                                                         @minitaur.CurrentVelWrapper,
                                                         @eval_monitor/misc.monitor_freq())
eval_monitor/misc.monitor_freq.freq = %EVAL_MONITOR_FREQ
eval_monitor/misc.monitor_freq.vid_dir = %EVAL_VID_DIR

TRAIN_METRICS = [
    @safemrl.utils.metrics.AverageEarlyFailureMetric(),
    @safemrl.utils.metrics.MinitaurAverageSpeedMetric(),
    @safemrl.utils.metrics.MinitaurAverageMaxSpeedMetric(),
]

# eval_failure/singleton.constructor = @safemrl.utils.metrics.AverageEarlyFailureMetric

EVAL_METRICS = [
    @safemrl.utils.metrics.AverageEarlyFailureMetric(),
    @safemrl.utils.metrics.MinitaurAverageSpeedMetric(),
    @safemrl.utils.metrics.MinitaurAverageMaxSpeedMetric()
]
# safemrl.utils.metrics.AverageEarlyFailureMetric.batch_size = %NUM_ENVS

minitaur.MinitaurGoalVelocityEnv.max_steps = %EP_LEN
safemrl.utils.metrics.AverageEarlyFailureMetric.max_episode_len = %EP_LEN
minitaur.MinitaurGoalVelocityEnv.accurate_motor_model_enabled = True
minitaur.MinitaurGoalVelocityEnv.never_terminate = False
minitaur.MinitaurGoalVelocityEnv.history_length = 5
minitaur.MinitaurGoalVelocityEnv.urdf_version = "rainbow_dash_v0"
minitaur.MinitaurGoalVelocityEnv.history_include_actions = True
minitaur.MinitaurGoalVelocityEnv.control_time_step = 0.02
minitaur.MinitaurGoalVelocityEnv.history_include_states = True
minitaur.MinitaurGoalVelocityEnv.include_leg_model = True

minitaur.MinitaurGoalVelocityEnv.goal_limit = 0.8
minitaur.MinitaurGoalVelocityEnv.goal_vel = 0.4
minitaur.MinitaurGoalVelocityEnv.butterworth = True

actor_distribution_network.ActorDistributionNetwork.preprocessing_combiner = (
    @misc.extract_observation_layer()
)

agents.CriticNetwork.preprocessing_combiner = (
    @misc.extract_obs_merge_w_ac_layer()
)