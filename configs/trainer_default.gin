include 'default_macros.gin'
import tf_agents.policies.actor_policy

# TRAINER BINDINGS
trainer.train_eval.env_name = %ENV_STR
trainer.train_eval.env_load_fn = %ENV_LOAD_FN
trainer.train_eval.gym_env_wrappers = %ENV_WRAPPERS
trainer.train_eval.agent_class = %AGENT_CLASS
trainer.train_eval.train_metrics = %TRAIN_METRICS
trainer.train_eval.eval_metrics = %EVAL_METRICS
trainer.train_eval.env_metric_factories = %ENV_METRIC_FACTORIES
trainer.train_eval.num_global_steps = %NUM_STEPS
trainer.train_eval.online_critic = False
trainer.train_eval.num_eval_episodes = %NUM_EVAL
trainer.train_eval.keep_rb_checkpoint = True

## TRAINER DRIVER BINDINGS
trainer.train_eval.initial_collect_driver_class = @init_collect/dynamic_step_driver.DynamicStepDriver
init_collect/dynamic_step_driver.DynamicStepDriver.num_steps = %INITIAL_NUM_STEPS
trainer.train_eval.collect_driver_class = @collect_driver/dynamic_step_driver.DynamicStepDriver
collect_driver/dynamic_step_driver.DynamicStepDriver.num_steps = 1

# MISC
agents.normal_projection_net.scale_distribution = True
# agents.normal_projection_net.init_means_output_factor = 0.1
agents.normal_projection_net.state_dependent_std = True