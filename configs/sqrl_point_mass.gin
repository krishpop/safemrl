import gin.tf.external_configurables
import tensorflow
import tf_agents.environments.suite_pybullet
import tf_agents.agents.ddpg.critic_network
import tf_agents.networks.actor_distribution_network

import safemrl.trainer
import safemrl.algos.ensemble_sac_agent

include 'sqrl.gin'
include 'point_mass_default.gin'

EP_LEN = 30
INITIAL_NUM_STEPS = 500
NUM_STEPS = 50000
TARGET_SAFETY = 0.4
SAFETY_GAMMA = 0.4

agents.normal_projection_net.init_means_output_factor = 0.01

safe_sac_agent.SqrlAgent.target_update_tau = 0.01
trainer.train_eval.lambda_initial = 1.
trainer.train_eval.kstep_fail = 0

# safe_sac_agent.SqrlAgent.target_entropy = -2
safe_sac_agent.SqrlAgent.gamma = 1.
safe_sac_agent.SqrlAgent.initial_log_alpha = 0.

# point_mass.PointMassEnv.start = (0, 6)
# point_mass.GoalConditionedPointWrapper.goal = (7, 6)
# point_mass.GoalConditionedPointWrapper.goal_bounds=[(6,4), (7,8)]
point_mass.PointMassEnv.action_scale = 1.
point_mass.PointMassEnv.action_noise = 0.
point_mass.GoalConditionedPointWrapper.task_rew_type = "l2"

# point_mass.TimeLimitBonus.early_term_penalty = 0.
# point_mass.TimeLimitBonus.early_term_bonus = 0.
# point_mass.TimeLimitBonus.time_limit_penalty = -60.

point_mass.TimeLimitBonus.early_term_penalty = 1.
point_mass.TimeLimitBonus.early_term_bonus = 1.
point_mass.TimeLimitBonus.time_limit_penalty = -30.

# point_mass.env_load_fn.resize_factor = (1, 2)
# point_mass.env_load_fn.fall_penalty = -10.